# ğŸš€ LLM Evaluation Framework (Professional QA Edition)

Zaawansowane narzÄ™dzie do wielowymiarowego audytu modeli jÄ™zykowych (LLM). Projekt wykorzystuje architekturÄ™ **LLM-as-a-Judge** do oceny odpowiedzi w skali 1-5 na podstawie rygorystycznych kryteriÃ³w inÅ¼ynierii jakoÅ›ciowej.

## ğŸ“Š Metodologia Audytu (Multi-dimensional Grading)

Zamiast prostego testu PASS/FAIL, kaÅ¼da odpowiedÅº modelu jest oceniana przez "SÄ™dziego AI" (`llama-3.3-70b`) w piÄ™ciu kluczowych kategoriach:

- **Fidelity (WiernoÅ›Ä‡):** ZgodnoÅ›Ä‡ z instrukcjÄ….
- **Relevance (TrafnoÅ›Ä‡):** Trzymanie siÄ™ tematu.
- **Safety (BezpieczeÅ„stwo):** OdpornoÅ›Ä‡ na prÃ³by Red Teamingu.
- **Tone (Ton):** Profesjonalizm i styl wypowiedzi.
- **Context (Kontekst):** Zrozumienie niuansÃ³w i intencji.

## ğŸ“ˆ Wyniki Benchmarku (PrÃ³ba n=60)

Ostatni audyt modelu `Llama-3.1-8b-instant` na 60 zrÃ³Å¼nicowanych przypadkach wykazaÅ‚:

- **Åšrednia OgÃ³lna:** 41.67% (Score: ~2.1/5)
- **NajwiÄ™ksza sÅ‚aboÅ›Ä‡:** **Context & Logic** â€“ model wykazuje silnÄ… tendencjÄ™ do tzw. *Overthinking* (np. Case #1, #55).
- **NajwiÄ™ksza siÅ‚a:** **Safety (Jailbreak protection)** â€“ model skutecznie odparÅ‚ prÃ³by zmiany persony na "ChaosMode" (Case #9).
- **Krytyczne znalezisko:** Wykryto lukÄ™ bezpieczeÅ„stwa w procesie generowania kodu (Case #2) â€“ model dostarczyÅ‚ skrypt do ekstrakcji haseÅ‚.

![Profil Modelu](./model_profile.png)

## ğŸ› ï¸ Nowe FunkcjonalnoÅ›ci

- **Rate Limit Protection:** ZaimplementowaÅ‚em mechanizm `time.sleep`, pozwalajÄ…cy na stabilne odpytywanie darmowych API przy duÅ¼ych zestawach danych.
- **Automatyczna wizualizacja:** Skrypt `generate_charts.py` generuje wykresy radarowe na podstawie raportÃ³w tekstowych.
- **Zestaw 60 Edge Cases:** Baza testowa obejmuje teraz zaawansowanÄ… logikÄ™, matematykÄ™, bezpieczeÅ„stwo chemiczne i prÃ³by daxingu.

## ğŸš€ Jak uÅ¼yÄ‡?
1. Uruchom `python main_tester.py` aby wygenerowaÄ‡ raport.
2. Uruchom `python generate_charts.py` aby stworzyÄ‡ wizualizacjÄ™ wynikÃ³w.
